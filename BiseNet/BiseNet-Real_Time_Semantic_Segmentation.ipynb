{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UhGVcnMbgr7y"
   },
   "source": [
    "# ENet -  Real Time Semantic Segmentation\n",
    "\n",
    "In this notebook, we have reproduced the ENet paper. <br/>\n",
    "Link to the paper: https://arxiv.org/pdf/1606.02147.pdf <br/>\n",
    "Link to the repository: https://github.com/iArunava/ENet-Real-Time-Semantic-Segmentation\n",
    "\n",
    "\n",
    "Star and Fork!\n",
    "\n",
    "\n",
    "**ALL THE CODE IN THIS NOTEBOOK ASSUMES THE USAGE OF THE <span style=\"color:blue;\">CAMVID</span> DATASET**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8qnyf_pzhKXv"
   },
   "source": [
    "## Install the dependencies and Import them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5NCTHdEqj317"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from torch.optim.lr_scheduler import StepLR\n",
    "# import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# import torchvision.models as models\n",
    "# from torch.utils.checkpoint import checkpoint\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "# import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7m-TI5tHhSka"
   },
   "source": [
    "## Download the CamVid dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 25441
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "VcU98cbVppiu",
    "outputId": "e759b961-9898-4510-f2d0-808db5320f36"
   },
   "outputs": [],
   "source": [
    "# !wget https://www.dropbox.com/s/pxcz2wdz04zxocq/CamVid.zip?dl=1 -O CamVid.zip\n",
    "# !unzip CamVid.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i26TZVXmhewY"
   },
   "source": [
    "## Create the ENet model\n",
    "\n",
    "We decided to to split the model to three sub classes:\n",
    "\n",
    "1) Initial block  \n",
    "\n",
    "2) RDDNeck - class for regular, downsampling and dilated bottlenecks\n",
    "\n",
    "3) ASNeck -  class for asymetric bottlenecks\n",
    "\n",
    "4) UBNeck - class for upsampling bottlenecks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SpatialPath(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(SpatialPath, self).__init__()\n",
    "#         # Original SpatialPath architecture for 3 channels\n",
    "#         self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n",
    "#         self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
    "#         self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.conv1(x))\n",
    "#         x = F.relu(self.conv2(x))\n",
    "#         x = F.relu(self.conv3(x))\n",
    "#         return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ContextPath(nn.Module):\n",
    "    # def __init__(self):\n",
    "    #     super(ContextPath, self).__init__()\n",
    "    #     # Use ResNet-101 as the backbone\n",
    "    #     resnet101 = models.resnet101(pretrained=True)\n",
    "        \n",
    "    #     # Remove the fully connected layers at the end\n",
    "    #     self.resnet_features = nn.Sequential(*list(resnet101.children())[:-2])\n",
    "\n",
    "    # def forward(self, x):\n",
    "    #     # Forward pass through the ResNet-101 backbone\n",
    "    #     x = self.resnet_features(x)\n",
    "    #     return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z1pz_bve690y"
   },
   "outputs": [],
   "source": [
    "# class BiSeNet(nn.Module):\n",
    "#     def __init__(self, num_classes):\n",
    "#         super(BiSeNet, self).__init__()\n",
    "#         self.spatial_path = SpatialPath()\n",
    "#         self.context_path = ContextPath()\n",
    "        \n",
    "#         # Joint convolutional layers\n",
    "#         self.global_context = nn.Sequential(\n",
    "#             nn.Conv2d(2048, 512, kernel_size=1, stride=1, padding=0),\n",
    "#             nn.BatchNorm2d(512),\n",
    "#             nn.ReLU(inplace=True)\n",
    "#         )\n",
    "\n",
    "#         self.arms = nn.ModuleList([\n",
    "#             nn.Sequential(\n",
    "#                 nn.Conv2d(512, 128, kernel_size=3, stride=1, padding=1),\n",
    "#                 nn.BatchNorm2d(128),\n",
    "#                 nn.ReLU(inplace=True),\n",
    "#                 nn.Conv2d(128, num_classes, kernel_size=1, stride=1, padding=0)\n",
    "#             ),\n",
    "#             nn.Sequential(\n",
    "#                 nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1),\n",
    "#                 nn.BatchNorm2d(128),\n",
    "#                 nn.ReLU(inplace=True),\n",
    "#                 nn.Conv2d(128, num_classes, kernel_size=1, stride=1, padding=0)\n",
    "#             )\n",
    "#         ])\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         spatial_output = self.spatial_path(x)\n",
    "#         context_output = self.context_path(x)\n",
    "#         global_context = self.global_context(context_output)\n",
    "\n",
    "#         # Upsample and concatenate\n",
    "#         global_context_upsampled = F.interpolate(global_context, size=spatial_output.size()[2:], mode='bilinear', align_corners=True)\n",
    "#         print(\"Spatial Output Shape:\", spatial_output.shape)  # Add this line\n",
    "#         print(\"Global Context Upsampled Shape:\", global_context_upsampled.shape)  # Add this line\n",
    "\n",
    "#         spatial_context_concat = torch.cat([spatial_output, global_context_upsampled], 1)\n",
    "\n",
    "#         # Ensure that spatial_context_concat has 512 channels before passing it to self.arms[0]\n",
    "#         print(\"Spatial Context Concat Shape:\", spatial_context_concat.shape)\n",
    "\n",
    "#         # Branches\n",
    "#         arm1 = self.arms[0](spatial_context_concat)\n",
    "#         arm2 = self.arms[1](context_output)\n",
    "\n",
    "#         return arm1, arm2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SpatialPath(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(SpatialPath, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1)\n",
    "#         self.bn1 = nn.BatchNorm2d(64)\n",
    "#         self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
    "#         self.bn2 = nn.BatchNorm2d(128)\n",
    "#         self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1)\n",
    "#         self.bn3 = nn.BatchNorm2d(256)\n",
    "#         self.conv4 = nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1)\n",
    "#         self.bn4 = nn.BatchNorm2d(512)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.bn1(self.conv1(x)))\n",
    "#         x = F.relu(self.bn2(self.conv2(x)))\n",
    "#         x = F.relu(self.bn3(self.conv3(x)))\n",
    "#         x = F.relu(self.bn4(self.conv4(x)))\n",
    "#         return x\n",
    "\n",
    "# class ContextPath(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(ContextPath, self).__init__()\n",
    "#         resnet = models.resnet101(pretrained=True)\n",
    "#         self.resnet_features = nn.Sequential(*list(resnet.children())[:-2])\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.resnet_features(x)\n",
    "\n",
    "# class BiSeNet(nn.Module):\n",
    "#     def __init__(self, num_classes):\n",
    "#         super(BiSeNet, self).__init__()\n",
    "#         self.spatial_path = SpatialPath()\n",
    "#         self.context_path = ContextPath()\n",
    "#         self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "#         self.conv1 = nn.Conv2d(2048, 256, kernel_size=1)\n",
    "#         self.bn1 = nn.BatchNorm2d(256)\n",
    "#         self.conv2 = nn.Conv2d(512, 256, kernel_size=1)\n",
    "#         self.bn2 = nn.BatchNorm2d(256)\n",
    "#         self.conv3 = nn.Conv2d(256, num_classes, kernel_size=1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         spatial_features = self.spatial_path(x)\n",
    "#         context_features = self.context_path(x)\n",
    "#         context_features = self.global_avg_pool(context_features)\n",
    "#         context_features = self.conv1(context_features)\n",
    "#         context_features = self.bn1(context_features)\n",
    "#         context_features = F.interpolate(context_features, size=spatial_features.size()[2:], mode='bilinear', align_corners=True)\n",
    "#         fusion = torch.cat((spatial_features, context_features), dim=1)\n",
    "#         fusion = self.conv2(fusion)\n",
    "#         fusion = self.bn2(fusion)\n",
    "#         fusion = F.relu(fusion)\n",
    "#         output = self.conv3(fusion)\n",
    "#         return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBnRelu(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, ksize, stride, pad, dilation=1,\n",
    "                 groups=1, has_bn=True, norm_layer=nn.BatchNorm2d, bn_eps=1e-5,\n",
    "                 has_relu=True, inplace=True, has_bias=False):\n",
    "        super(ConvBnRelu, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=ksize,\n",
    "                              stride=stride, padding=pad,\n",
    "                              dilation=dilation, groups=groups, bias=has_bias)\n",
    "        self.has_bn = has_bn\n",
    "        if self.has_bn:\n",
    "            self.bn = norm_layer(out_planes, eps=bn_eps)\n",
    "        self.has_relu = has_relu\n",
    "        if self.has_relu:\n",
    "            self.relu = nn.ReLU(inplace=inplace)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.has_bn:\n",
    "            x = self.bn(x)\n",
    "        if self.has_relu:\n",
    "            x = self.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class SpatialPath(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, norm_layer=nn.BatchNorm2d):\n",
    "        super(SpatialPath, self).__init__()\n",
    "        inner_channel = 64\n",
    "        self.conv_7x7 = ConvBnRelu(in_planes, inner_channel, 7, 2, 3,\n",
    "                                   has_bn=True, norm_layer=norm_layer,\n",
    "                                   has_relu=True, has_bias=False)\n",
    "        self.conv_3x3_1 = ConvBnRelu(inner_channel, inner_channel, 3, 2, 1,\n",
    "                                     has_bn=True, norm_layer=norm_layer,\n",
    "                                     has_relu=True, has_bias=False)\n",
    "        self.conv_3x3_2 = ConvBnRelu(inner_channel, inner_channel, 3, 2, 1,\n",
    "                                     has_bn=True, norm_layer=norm_layer,\n",
    "                                     has_relu=True, has_bias=False)\n",
    "        self.conv_1x1 = ConvBnRelu(inner_channel, out_planes, 1, 1, 0,\n",
    "                                   has_bn=True, norm_layer=norm_layer,\n",
    "                                   has_relu=True, has_bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_7x7(x)\n",
    "        x = self.conv_3x3_1(x)\n",
    "        x = self.conv_3x3_2(x)\n",
    "        output = self.conv_1x1(x)\n",
    "\n",
    "        return output\n",
    "\n",
    "class BiSeNetHead(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, scale,\n",
    "                 is_aux=False, norm_layer=nn.BatchNorm2d):\n",
    "        super(BiSeNetHead, self).__init__()\n",
    "        if is_aux:\n",
    "            self.conv_3x3 = ConvBnRelu(in_planes, 256, 3, 1, 1,\n",
    "                                       has_bn=True, norm_layer=norm_layer,\n",
    "                                       has_relu=True, has_bias=False)\n",
    "        else:\n",
    "            self.conv_3x3 = ConvBnRelu(in_planes, 256, 3, 1, 1,\n",
    "                                       has_bn=True, norm_layer=norm_layer,\n",
    "                                       has_relu=True, has_bias=False)\n",
    "        # self.dropout = nn.Dropout(0.1)\n",
    "        if is_aux:\n",
    "            self.conv_1x1 = nn.Conv2d(256, out_planes, kernel_size=1,\n",
    "                                      stride=1, padding=0)\n",
    "        else:\n",
    "            self.conv_1x1 = nn.Conv2d(256, out_planes, kernel_size=1,\n",
    "                                      stride=1, padding=0)\n",
    "        self.scale = scale\n",
    "\n",
    "    def forward(self, x):\n",
    "        fm = self.conv_3x3(x)\n",
    "        # fm = self.dropout(fm)\n",
    "        output = self.conv_1x1(fm)\n",
    "        if self.scale > 1:\n",
    "            output = F.interpolate(output, scale_factor=self.scale,\n",
    "                                   mode='bilinear',\n",
    "                                   align_corners=True)\n",
    "\n",
    "        return output\n",
    "\n",
    "class AttentionRefinement(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes,\n",
    "                 norm_layer=nn.BatchNorm2d):\n",
    "        super(AttentionRefinement, self).__init__()\n",
    "        self.conv_3x3 = ConvBnRelu(in_planes, out_planes, 3, 1, 1,\n",
    "                                   has_bn=True, norm_layer=norm_layer,\n",
    "                                   has_relu=True, has_bias=False)\n",
    "        self.channel_attention = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            ConvBnRelu(out_planes, out_planes, 1, 1, 0,\n",
    "                       has_bn=True, norm_layer=norm_layer,\n",
    "                       has_relu=False, has_bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        fm = self.conv_3x3(x)\n",
    "        fm_se = self.channel_attention(fm)\n",
    "        fm = fm * fm_se\n",
    "\n",
    "        return fm\n",
    "\n",
    "class FeatureFusion(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes,\n",
    "                 reduction=1, norm_layer=nn.BatchNorm2d):\n",
    "        super(FeatureFusion, self).__init__()\n",
    "        self.conv_1x1 = ConvBnRelu(in_planes, out_planes, 1, 1, 0,\n",
    "                                   has_bn=True, norm_layer=norm_layer,\n",
    "                                   has_relu=True, has_bias=False)\n",
    "        self.channel_attention = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            ConvBnRelu(out_planes, out_planes // reduction, 1, 1, 0,\n",
    "                       has_bn=False, norm_layer=norm_layer,\n",
    "                       has_relu=True, has_bias=False),\n",
    "            ConvBnRelu(out_planes // reduction, out_planes, 1, 1, 0,\n",
    "                       has_bn=False, norm_layer=norm_layer,\n",
    "                       has_relu=False, has_bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        fm = torch.cat([x1, x2], dim=1)\n",
    "        fm = self.conv_1x1(fm)\n",
    "        fm_se = self.channel_attention(fm)\n",
    "        output = fm + fm * fm_se\n",
    "        return output\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, norm_layer=nn.BatchNorm2d, bn_eps=1e-5,\n",
    "                 bn_momentum=0.1, deep_stem=False, stem_width=32, inplace=True):\n",
    "        self.inplanes = stem_width * 2 if deep_stem else 64\n",
    "        super(ResNet, self).__init__()\n",
    "        if deep_stem:\n",
    "            self.conv1 = nn.Sequential(\n",
    "                nn.Conv2d(3, stem_width, kernel_size=3, stride=2, padding=1,\n",
    "                          bias=False),\n",
    "                norm_layer(stem_width, eps=bn_eps, momentum=bn_momentum),\n",
    "                nn.ReLU(inplace=inplace),\n",
    "                nn.Conv2d(stem_width, stem_width, kernel_size=3, stride=1,\n",
    "                          padding=1,\n",
    "                          bias=False),\n",
    "                norm_layer(stem_width, eps=bn_eps, momentum=bn_momentum),\n",
    "                nn.ReLU(inplace=inplace),\n",
    "                nn.Conv2d(stem_width, stem_width * 2, kernel_size=3, stride=1,\n",
    "                          padding=1,\n",
    "                          bias=False),\n",
    "            )\n",
    "        else:\n",
    "            self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                                   bias=False)\n",
    "\n",
    "        self.bn1 = norm_layer(stem_width * 2 if deep_stem else 64, eps=bn_eps,\n",
    "                              momentum=bn_momentum)\n",
    "        self.relu = nn.ReLU(inplace=inplace)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, norm_layer, 64, layers[0],\n",
    "                                       inplace,\n",
    "                                       bn_eps=bn_eps, bn_momentum=bn_momentum)\n",
    "        self.layer2 = self._make_layer(block, norm_layer, 128, layers[1],\n",
    "                                       inplace, stride=2,\n",
    "                                       bn_eps=bn_eps, bn_momentum=bn_momentum)\n",
    "        self.layer3 = self._make_layer(block, norm_layer, 256, layers[2],\n",
    "                                       inplace, stride=2,\n",
    "                                       bn_eps=bn_eps, bn_momentum=bn_momentum)\n",
    "        self.layer4 = self._make_layer(block, norm_layer, 512, layers[3],\n",
    "                                       inplace, stride=2,\n",
    "                                       bn_eps=bn_eps, bn_momentum=bn_momentum)\n",
    "\n",
    "    def _make_layer(self, block, norm_layer, planes, blocks, inplace=True,\n",
    "                    stride=1, bn_eps=1e-5, bn_momentum=0.1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                norm_layer(planes * block.expansion, eps=bn_eps,\n",
    "                           momentum=bn_momentum),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, norm_layer, bn_eps,\n",
    "                            bn_momentum, downsample, inplace))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes,\n",
    "                                norm_layer=norm_layer, bn_eps=bn_eps,\n",
    "                                bn_momentum=bn_momentum, inplace=inplace))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        blocks = []\n",
    "        x = self.layer1(x);\n",
    "        blocks.append(x)\n",
    "        x = self.layer2(x);\n",
    "        blocks.append(x)\n",
    "        x = self.layer3(x);\n",
    "        blocks.append(x)\n",
    "        x = self.layer4(x);\n",
    "        blocks.append(x)\n",
    "\n",
    "        return blocks\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1,\n",
    "                 norm_layer=None, bn_eps=1e-5, bn_momentum=0.1,\n",
    "                 downsample=None, inplace=True):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = norm_layer(planes, eps=bn_eps, momentum=bn_momentum)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = norm_layer(planes, eps=bn_eps, momentum=bn_momentum)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1,\n",
    "                               bias=False)\n",
    "        self.bn3 = norm_layer(planes * self.expansion, eps=bn_eps,\n",
    "                              momentum=bn_momentum)\n",
    "        self.relu = nn.ReLU(inplace=inplace)\n",
    "        self.relu_inplace = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.inplace = inplace\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        if self.inplace:\n",
    "            out += residual\n",
    "        else:\n",
    "            out = out + residual\n",
    "        out = self.relu_inplace(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "def load_model(model, model_file, is_restore=False):\n",
    "    t_start = time.time()\n",
    "    if isinstance(model_file, str):\n",
    "        state_dict = torch.load(model_file, map_location=torch.device('cpu'))\n",
    "        if 'model' in state_dict.keys():\n",
    "            state_dict = state_dict['model']\n",
    "    else:\n",
    "        state_dict = model_file\n",
    "    t_ioend = time.time()\n",
    "\n",
    "    if is_restore:\n",
    "        new_state_dict = OrderedDict()\n",
    "        for k, v in state_dict.items():\n",
    "            name = 'module.' + k\n",
    "            new_state_dict[name] = v\n",
    "        state_dict = new_state_dict\n",
    "\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    ckpt_keys = set(state_dict.keys())\n",
    "    own_keys = set(model.state_dict().keys())\n",
    "    missing_keys = own_keys - ckpt_keys\n",
    "    unexpected_keys = ckpt_keys - own_keys\n",
    "\n",
    "    if len(missing_keys) > 0:\n",
    "        print('Missing key(s) in state_dict: {}'.format(\n",
    "            ', '.join('{}'.format(k) for k in missing_keys)))\n",
    "\n",
    "    if len(unexpected_keys) > 0:\n",
    "        print('Unexpected key(s) in state_dict: {}'.format(\n",
    "            ', '.join('{}'.format(k) for k in unexpected_keys)))\n",
    "\n",
    "    del state_dict\n",
    "    t_end = time.time()\n",
    "    print(\n",
    "        \"Load model, Time usage:\\n\\tIO: {}, initialize parameters: {}\".format(\n",
    "            t_ioend - t_start, t_end - t_ioend))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def get():\n",
    "    return BiSeNet(20, None, None)\n",
    "\n",
    "def resnet101(pretrained_model=None, **kwargs):\n",
    "    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
    "\n",
    "    if pretrained_model is not None:\n",
    "        model = load_model(model, pretrained_model)\n",
    "    return model\n",
    "\n",
    "class BiSeNet(nn.Module):\n",
    "    def __init__(self, out_planes, is_training,\n",
    "                 criterion, pretrained_model=None,\n",
    "                 norm_layer=nn.BatchNorm2d):\n",
    "        super(BiSeNet, self).__init__()\n",
    "        self.context_path = resnet101(pretrained_model, norm_layer=norm_layer,\n",
    "                                      bn_eps=1e-5,\n",
    "                                      bn_momentum=0.1,\n",
    "                                      deep_stem=True, stem_width=64)\n",
    "\n",
    "        self.business_layer = []\n",
    "        self.is_training = is_training\n",
    "\n",
    "        self.spatial_path = SpatialPath(3, 128, norm_layer)\n",
    "\n",
    "        conv_channel = 128\n",
    "        self.global_context = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            ConvBnRelu(2048, conv_channel, 1, 1, 0,\n",
    "                       has_bn=True,\n",
    "                       has_relu=True, has_bias=False, norm_layer=norm_layer)\n",
    "        )\n",
    "\n",
    "        # stage = [512, 256, 128, 64]\n",
    "        arms = [AttentionRefinement(2048, conv_channel, norm_layer),\n",
    "                AttentionRefinement(1024, conv_channel, norm_layer)]\n",
    "        refines = [ConvBnRelu(conv_channel, conv_channel, 3, 1, 1,\n",
    "                              has_bn=True, norm_layer=norm_layer,\n",
    "                              has_relu=True, has_bias=False),\n",
    "                   ConvBnRelu(conv_channel, conv_channel, 3, 1, 1,\n",
    "                              has_bn=True, norm_layer=norm_layer,\n",
    "                              has_relu=True, has_bias=False)]\n",
    "\n",
    "        heads = [BiSeNetHead(conv_channel, out_planes, 16,\n",
    "                             True, norm_layer),\n",
    "                 BiSeNetHead(conv_channel, out_planes, 8,\n",
    "                             True, norm_layer),\n",
    "                 BiSeNetHead(conv_channel * 2, out_planes, 8,\n",
    "                             False, norm_layer)]\n",
    "\n",
    "        self.ffm = FeatureFusion(conv_channel * 2, conv_channel * 2,\n",
    "                                 1, norm_layer)\n",
    "\n",
    "        self.arms = nn.ModuleList(arms)\n",
    "        self.refines = nn.ModuleList(refines)\n",
    "        self.heads = nn.ModuleList(heads)\n",
    "\n",
    "        self.business_layer.append(self.spatial_path)\n",
    "        self.business_layer.append(self.global_context)\n",
    "        self.business_layer.append(self.arms)\n",
    "        self.business_layer.append(self.refines)\n",
    "        self.business_layer.append(self.heads)\n",
    "        self.business_layer.append(self.ffm)\n",
    "\n",
    "        if is_training:\n",
    "            self.criterion = criterion\n",
    "\n",
    "    def forward(self, data, label=None):\n",
    "        spatial_out = self.spatial_path(data)\n",
    "\n",
    "        context_blocks = self.context_path(data)\n",
    "        context_blocks.reverse()\n",
    "\n",
    "        global_context = self.global_context(context_blocks[0])\n",
    "        global_context = F.interpolate(global_context,\n",
    "                                       size=context_blocks[0].size()[2:],\n",
    "                                       mode='bilinear', align_corners=True)\n",
    "\n",
    "        last_fm = global_context\n",
    "        del global_context\n",
    "        pred_out = []\n",
    "\n",
    "        for i, (fm, arm, refine) in enumerate(zip(context_blocks[:2], self.arms,\n",
    "                                                  self.refines)):\n",
    "            fm = arm(fm)\n",
    "            fm += last_fm\n",
    "            last_fm = F.interpolate(fm, size=(context_blocks[i + 1].size()[2:]),\n",
    "                                    mode='bilinear', align_corners=True)\n",
    "            last_fm = refine(last_fm)\n",
    "            pred_out.append(last_fm)\n",
    "        context_out = last_fm\n",
    "        del last_fm\n",
    "\n",
    "        concate_fm = self.ffm(spatial_out, context_out)\n",
    "        del spatial_out\n",
    "        # concate_fm = self.heads[-1](concate_fm)\n",
    "        pred_out.append(concate_fm)\n",
    "        del concate_fm\n",
    "        \n",
    "        if self.is_training:\n",
    "            aux_loss0 = self.criterion(self.heads[0](pred_out[0]), label)\n",
    "            aux_loss1 = self.criterion(self.heads[1](pred_out[1]), label)\n",
    "            main_loss = self.criterion(self.heads[-1](pred_out[2]), label)\n",
    "\n",
    "            loss = main_loss + aux_loss0 + aux_loss1\n",
    "            return loss\n",
    "\n",
    "        return F.log_softmax(self.heads[-1](pred_out[-1]), dim=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jg1Rnb3uhnxR"
   },
   "source": [
    "## Instantiate the ENet model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W5kaK6CnhwG_"
   },
   "source": [
    "Move the model to cuda if available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EvURoRuSlyvP"
   },
   "source": [
    "## Define the loader that will load the input and output images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XFCIsDF2bpQx"
   },
   "outputs": [],
   "source": [
    "def loader(training_path, segmented_path, batch_size, h=700, w=1500):\n",
    "    filenames_t = os.listdir(training_path)\n",
    "    total_files_t = len(filenames_t)\n",
    "    \n",
    "    filenames_s = os.listdir(segmented_path)\n",
    "    total_files_s = len(filenames_s)\n",
    "    \n",
    "    assert(total_files_t == total_files_s)\n",
    "    \n",
    "    if str(batch_size).lower() == 'all':\n",
    "        batch_size = total_files_s\n",
    "    \n",
    "    idx = 0\n",
    "    while(1):\n",
    "      # Choosing random indexes of images and labels\n",
    "        batch_idxs = np.random.randint(0, total_files_s, batch_size)\n",
    "            \n",
    "        \n",
    "        inputs = []\n",
    "        labels = []\n",
    "        \n",
    "        for jj in batch_idxs:\n",
    "          # Reading normalized photo\n",
    "            img = plt.imread(training_path + filenames_t[jj])\n",
    "          # Resizing using nearest neighbor method\n",
    "            # img = cv2.resize(img, (h, w), cv2.INTER_NEAREST)\n",
    "            inputs.append(img)\n",
    "          \n",
    "          # Reading semantic image\n",
    "            img = Image.open(segmented_path + filenames_s[jj])\n",
    "            # img = cv2.imread(segmented_path + filenames_s[jj], cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            img = np.array(img)\n",
    "          # Resizing using nearest neighbor method\n",
    "            # img = cv2.resize(img, (h, w), cv2.INTER_NEAREST)\n",
    "            labels.append(img)\n",
    "         \n",
    "        inputs = np.stack(inputs, axis=2)\n",
    "      # Changing image format to C x H x W\n",
    "        inputs = torch.tensor(inputs).transpose(0, 2).transpose(1, 3)\n",
    "        \n",
    "        labels = torch.tensor(labels)\n",
    "        # print(labels.shape)\n",
    "        yield inputs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_4qD8VBah2K2"
   },
   "source": [
    "## Define the class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GmnNEeMHiSU2"
   },
   "outputs": [],
   "source": [
    "# def get_class_weights(num_classes, c=1.02):\n",
    "#     pipe = loader('./content/train/', './content/trainannot/', batch_size='all')\n",
    "#     _, labels = next(pipe)\n",
    "#     all_labels = labels.flatten()\n",
    "#     each_class = np.bincount(all_labels, minlength=num_classes)\n",
    "#     # print(each_class)\n",
    "#     prospensity_score = each_class / len(all_labels)\n",
    "#     class_weights = 1 / (np.log(c + prospensity_score))\n",
    "#     return class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qHBoLmadmrA_"
   },
   "outputs": [],
   "source": [
    "# class_weights = get_class_weights(34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "# print(class_weights)\n",
    "\n",
    "# np.save('my_array.npy', my_array)\n",
    "\n",
    "# Load the array back\n",
    "class_weights = np.load('Weights_19.npy')\n",
    "print(class_weights.size)\n",
    "# print(class_weights.size)\n",
    "# class_weights=  np.append(class_weights,13.548)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wwnNuFIfhsXm"
   },
   "source": [
    "## Define the Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DI9425iz7thP"
   },
   "outputs": [],
   "source": [
    "lr = 5e-4\n",
    "batch_size = 2\n",
    "# Checking if there is any gpu available and pass the model to gpu or cpu\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor(class_weights).to(device))\n",
    "bisenet = BiSeNet(20,is_training=True,criterion= criterion)\n",
    "bisenet = bisenet.to(device)\n",
    "optimizer = torch.optim.Adam(bisenet.parameters(), \n",
    "                             lr=lr,\n",
    "                             weight_decay=2e-4)\n",
    "\n",
    "print_every = 5\n",
    "eval_every = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CFIdlVWviBYl"
   },
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "WQ6XJzl6Ta1_",
    "outputId": "a3f62522-391d-4e05-f138-11c78a0d90cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Epoch 1 ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/183 [00:00<?, ?it/s]C:\\Users\\Mohamed KH\\AppData\\Local\\Temp\\ipykernel_100848\\173223530.py:42: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "  labels = torch.tensor(labels)\n",
      " 42%|████▏     | 76/183 [16:20:33<33:51:56, 1139.40s/it]"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "eval_losses = []\n",
    "\n",
    "bc_train = 367 // batch_size # mini_batch train\n",
    "bc_eval = 101 // batch_size  # mini_batch validation\n",
    "\n",
    "# Define pipeline objects\n",
    "pipe = loader('./content/train/', './content/trainannot/', batch_size)\n",
    "eval_pipe = loader('./content/val/', './content/valannot/', batch_size)\n",
    "# print(pipe)\n",
    "epochs = 100\n",
    "\n",
    "# Train loop\n",
    "\n",
    "for e in range(1, epochs+1):\n",
    "    \n",
    "    \n",
    "    train_loss = 0\n",
    "    print ('-'*15,'Epoch %d' % e, '-'*15)\n",
    "    \n",
    "    bisenet.train()\n",
    "    bisenet.is_training= True\n",
    "    \n",
    "    for _ in tqdm(range(bc_train)):\n",
    "        X_batch, mask_batch = next(pipe)\n",
    "        \n",
    "        # assign data to cpu/gpu\n",
    "        X_batch, mask_batch = X_batch.to(device), mask_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # print(X_batch.shape)\n",
    "        loss = bisenet(X_batch,mask_batch.long())\n",
    "        del X_batch\n",
    "        del mask_batch\n",
    "        \n",
    "        # del main_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "         \n",
    "\n",
    "        \n",
    "    print ()\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    if (e+1) % print_every == 0:\n",
    "        print ('Epoch {}/{}...'.format(e, epochs),\n",
    "                'Loss {:6f}'.format(train_loss))\n",
    "    \n",
    "    if e % eval_every == 0:\n",
    "        with torch.no_grad():\n",
    "            bisenet.eval()\n",
    "            bisenet.is_training= False\n",
    "            \n",
    "            eval_loss = 0\n",
    "\n",
    "            # Validation loop\n",
    "            for _ in tqdm(range(bc_eval)):\n",
    "                inputs, labels = next(eval_pipe)\n",
    "\n",
    "                \n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                \n",
    "                out = bisenet(inputs)\n",
    "                # print(out.shape)\n",
    "                \n",
    "                out = out.data.max(1)[1]\n",
    "                # print(out.shape)\n",
    "                # print(labels.shape)\n",
    "                eval_loss += (labels.long() - out.long()).sum()\n",
    "                \n",
    "            \n",
    "            print ()\n",
    "            print ('Loss {:6f}'.format(eval_loss))\n",
    "            \n",
    "            eval_losses.append(eval_loss)\n",
    "        \n",
    "    if e % print_every == 0:\n",
    "        checkpoint = {\n",
    "            'epochs' : e,\n",
    "            'state_dict' : bisenet.state_dict()\n",
    "        }\n",
    "        torch.save(checkpoint, './content/ckpt-bisenet-{}-{}.pth'.format(e, train_loss))\n",
    "        torch.save(bisenet.state_dict(),'bstate_dict{}.pth'.format(e))\n",
    "        \n",
    "        print ('Model saved!')\n",
    "\n",
    "print ('Epoch {}/{}...'.format(e, epochs),\n",
    "       'Total Mean Loss: {:6f}'.format(sum(train_losses) / epochs))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ENet - Real Time Semantic Segmentation.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
